{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "",
  "signature": "sha256:cacf673690cc0259238a3f22225f596aebd1e9eca14cc0e38b66ec62c76829fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Get To The Point: Summarization with Pointer-Generator Networks\n",
      "\n",
      "Abstractive summarization based on [See et al. (2017)](https://nlp.stanford.edu/pubs/see2017get.pdf) based on a hybrid pointer network and generative model. This is an intermediary between standard sequence-to-sequence models (eg. Nallapati et al.) and the pointer network of Vinyals et al. We use the **DailyMail** dataset to train and evaluate the model.\n",
      "\n",
      "The Pointer-Generator Network computes a probability distribution over words found in the vocabulary (generator) and a distribution over words found in the source material (pointer). These are combined with a computed probability $P_{gen}$, the probability that a the next word will be generated from the vocabulary. The loss function is a combination of negative log likelihood of the ground truth next word and a regularization term which penalizes repeated attention to the same segment of the source material. The final loss function is then:\n",
      "$$loss_t=-\\text{log}P(w_t^*)+\\lambda\\sum_i\\text{min}(a_i^t,c_i^t)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Requirements\n",
      "\n",
      "You will need [PyTorch](http://pytorch.org/) to build and train the models, and [matplotlib](https://matplotlib.org/) for plotting training and visualizing attention outputs later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import unicodedata\n",
      "import string\n",
      "import re\n",
      "import random\n",
      "import time\n",
      "import math\n",
      "import csv\n",
      "import os\n",
      "import sys\n",
      "import heapq\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from torch.autograd import Variable\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "\n",
      "import os\n",
      "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6,7\"\n",
      "\n",
      "# number of files to be read (entire dataset is 17MB)\n",
      "num_files = 10\n",
      "vocab_size = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we will also define a constant to decide whether to use the GPU (with CUDA specifically) or the CPU. **If you don't have a GPU, set this to `False`**. Later when we create tensors, this variable will be used to decide whether we keep them on CPU or move them to GPU."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "USE_CUDA = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading data files\n",
      "\n",
      "The data for this project is a set of tokenized news articles from the DailyMail summarization corpus. The entries are located in separate files, and are organized with the article first, followed by a number of summary sentences. One sample file is as follows:\n",
      "```\n",
      "By\n",
      "Richard Spillett\n",
      "\n",
      "An electronic cigarette that exploded while charging in a car has prompted fresh safety fears over the product .\n",
      "\n",
      "Carer Kim Taylor , 54 , left the device on charge for just ten minutes before she noticed flames and thick black smoke billowing from the vehicle .\n",
      "\n",
      "No one was inside at the time , but the back seat was completely melted and the mother-of-two was horrified at the thought she and her family could have been injured .\n",
      "\n",
      "Scroll down for video\n",
      "\n",
      "Safety fear : Kim Taylor and her son Jake , 11 , had to extinguish a fire in her car after an e-cigarette exploded\n",
      "\n",
      "` I 've gone to sleep with it plugged in\n",
      "before , ' she said . ` I hate to think what would have happened if it had\n",
      "exploded next to me . '\n",
      "\n",
      "The\n",
      "battery-powered product is billed as a healthy alternative to real\n",
      "cigarettes as users inhale nicotine with no tar , tobacco or carbon\n",
      "monoxide .\n",
      "\n",
      "But there have\n",
      "been several cases of the device exploding while on charge and it is\n",
      "thought to have claimed its first victim in November last year .\n",
      "\n",
      "[...]\n",
      "\n",
      "Following the spate of incidents , fire investigator Charlie Pugsley said : ` People assume e-cigarettes are much safer than ordinary cigarettes , and in most cases they are .\n",
      "\n",
      "` The danger is that people sometimes use incorrect chargers which runs the risk of over-charging , which can potentially have explosive results . '\n",
      "\n",
      "@highlight\n",
      "\n",
      "Kim Taylor , 54 , left the device plugged in on back seat of Ford Mondeo\n",
      "\n",
      "@highlight\n",
      "\n",
      "But she returned minutes later to see smoke billowing from the vehicle\n",
      "\n",
      "@highlight\n",
      "\n",
      "She says the device exploded and burned a huge hole in her car seat\n",
      "\n",
      "@highlight\n",
      "\n",
      "Manufacturers say e-cigarettes must be used with the correct adapters\n",
      "\n",
      "@highlight\n",
      "\n",
      "The incident is the latest in a spate of fires attributed to e-cigarettes\n",
      "```\n",
      "\n",
      "For this summarization experiment, the data are stored in the `data/dm_stories_tokenized` folder."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language. On other tutorials,  they adopt an initial embedding matrix built from [GloVe](http://nlp.stanford.edu/projects/glove/), which can be tested afterwards."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indexing words\n",
      "\n",
      "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Voc` which has word &rarr; index (`word2index`) and index &rarr; word (`index2word`) dictionaries, as well as a count of each word `word2count` to use to later replace rare words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "SOS_token = 0\n",
      "EOS_token = 1\n",
      "OOV_token = 2\n",
      "\n",
      "class Voc:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "        self.word2index = {}\n",
      "        self.word2count = {}\n",
      "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"OOV\"}\n",
      "        self.n_words = 3 # Count SOS, EOS, and OOV\n",
      "\n",
      "    def index_words(self, sentence):\n",
      "        for word in sentence.split(' '):\n",
      "            self.index_word(word)\n",
      "\n",
      "    def index_word(self, word):\n",
      "        if word not in self.word2index:\n",
      "            self.word2index[word] = self.n_words\n",
      "            self.word2count[word] = 1\n",
      "            self.index2word[self.n_words] = word\n",
      "            self.n_words += 1\n",
      "        else:\n",
      "            self.word2count[word] += 1\n",
      "\n",
      "    # removes all except the top \n",
      "    # duke is very sorry about bad code style \n",
      "    def prune(self, count):\n",
      "        if count >= self.n_words - 3: return\n",
      "        top_words = heapq.nlargest(count, self.word2count.items(), key=lambda x:x[1])\n",
      "        self.word2count = dict(top_words)\n",
      "        self.word2index = dict(zip([word[0] for word in top_words], range(3, count + 4)))\n",
      "        self.index2word = dict(zip(range(3, count + 4), [word[0] for word in top_words]))\n",
      "        self.index2word[0] = \"SOS\"\n",
      "        self.index2word[1] = \"EOS\"\n",
      "        self.index2word[2] = \"OOV\"\n",
      "        self.n_words = count + 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Reading and decoding files\n",
      "\n",
      "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
      "def unicode_to_ascii(s):\n",
      "    return ''.join(\n",
      "        c for c in unicodedata.normalize('NFD', s)\n",
      "        if unicodedata.category(c) != 'Mn'\n",
      "    )\n",
      "\n",
      "# Lowercase, trim, and remove non-letter characters\n",
      "def normalize_string(s):\n",
      "    s = unicode_to_ascii(s.lower().strip())\n",
      "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
      "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
      "    return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To read the data file we will split the file into lines, and then split lines into pairs. The files are all description &rarr; headline, so if we want to generate text from headline &rarr; description I added the `reverse` flag to reverse the pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def read_stories(pathname, reverse=False):\n",
      "    print(\"Reading csv...\")\n",
      "    \n",
      "    # Get the first num_files file names\n",
      "    files = os.listdir('../data/%s' % pathname)[:num_files]\n",
      "    \n",
      "    # Boolean flag for summary sentences\n",
      "    summary_next = False\n",
      "    \n",
      "    # Read each file and extract vocab\n",
      "    pairs = []\n",
      "    for filename in files:\n",
      "        with open('../data/%s/%s' % (pathname, filename), 'r') as story_file:\n",
      "            story = ''\n",
      "            summary = ''\n",
      "            for line in story_file:\n",
      "                if line == '\\n': continue # ignore blank lines\n",
      "                if line == '@highlight\\n': summary_next = True\n",
      "                else:\n",
      "                    if summary_next: summary += line\n",
      "                    else: story += line\n",
      "                    summary_next = False\n",
      "            pairs.append([normalize_string(story), normalize_string(summary)])\n",
      "            \n",
      "    # Reverse pairs, make Lang instances (not supported)\n",
      "    if reverse:\n",
      "        pairs = [list(reversed(p)) for p in pairs]\n",
      "    voc = Voc(pathname)\n",
      "\n",
      "    return voc, pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preparing Data\n",
      "\n",
      "The full process for preparing the data is:\n",
      "\n",
      "* Read text file and split into lines, split lines into pairs\n",
      "* Make word lists from sentences in pairs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_data(pathname, reverse=False):\n",
      "    voc, pairs = read_stories(pathname, reverse)\n",
      "    print(\"Read %s sentence pairs\" % len(pairs))\n",
      "\n",
      "    print(\"Indexing words...\")\n",
      "    for pair in pairs:\n",
      "        voc.index_words(pair[0])\n",
      "        voc.index_words(pair[1])\n",
      "    voc.prune(vocab_size)\n",
      "    print(\"    found %d words\" % voc.n_words)\n",
      "\n",
      "    return voc, pairs\n",
      "\n",
      "voc, pairs = prepare_data('dm_stories_tokenized', False)\n",
      "\n",
      "#print(random.choice(pairs)[0])\n",
      "print(random.choice(pairs)[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading csv...\n",
        "Read 10 sentence pairs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Indexing words...\n",
        "    found 103 words\n",
        "giuliano saw a masked person holding a knife come toward him in a threatening manner and shot him he later was told the person was his son tyler giuliano a th grader when police officers arrived at the scene they found a distraught giuliano a fifth grade science teacher overwhelmed with grief\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Return a list of indexes, one for each word in the sentence\n",
      "def indexes_from_sentence(voc, sentence):\n",
      "    indexes = []\n",
      "    OOV_list = []\n",
      "    OOV_indexes = []\n",
      "    for pos, word in enumerate(sentence.split(' ')):\n",
      "        if word in voc.word2index:\n",
      "            indexes.append(voc.word2index[word])\n",
      "        else:\n",
      "            indexes.append(OOV_token)\n",
      "            if word not in OOV_list: OOV_list.append(word) # create a list of out-of-vocabulary words\n",
      "            OOV_indexes.append( (pos, OOV_list.index(word)) )\n",
      "    return indexes, OOV_list, OOV_indexes\n",
      "\n",
      "def variable_from_sentence(voc, sentence):\n",
      "    indexes, OOV_list, OOV_indexes = indexes_from_sentence(voc, sentence)\n",
      "    indexes.append(EOS_token)\n",
      "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
      "    print(\"Sentence shape: \", var.shape)\n",
      "#     print('var =', var)\n",
      "    if USE_CUDA: var = var.cuda()\n",
      "    return var, OOV_list, OOV_indexes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Building the models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class EncoderRNN(nn.Module):\n",
      "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
      "        super(EncoderRNN, self).__init__()\n",
      "        \n",
      "        self.input_size = input_size\n",
      "        self.hidden_size = hidden_size\n",
      "        self.n_layers = n_layers\n",
      "        \n",
      "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
      "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
      "        \n",
      "    def forward(self, word_inputs, hidden):\n",
      "        # Note: we run this all at once (over the whole input sequence)\n",
      "        seq_len = len(word_inputs)\n",
      "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
      "        output, hidden = self.gru(embedded, hidden)\n",
      "        return output, hidden\n",
      "\n",
      "    def init_hidden(self):\n",
      "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
      "        if USE_CUDA: hidden = hidden.cuda()\n",
      "        return hidden"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Attention Decoder"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting the Luong et al. model(s)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) by Luong et al. describe a few more attention models that offer improvements and simplifications. They describe a few \"global attention\" models, the distinction between them being the way the attention scores are calculated.\n",
      "\n",
      "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1:\n",
      "\n",
      "$$\n",
      "a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n",
      "$$\n",
      "\n",
      "The specific \"score\" function that compares two states is either *dot*, a simple dot product between the states; *general*, a a dot product between the decoder hidden state and a linear transform of the encoder state; or *concat*, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
      "\n",
      "$$\n",
      "score(h_t, \\bar h_s) =\n",
      "\\begin{cases}\n",
      "h_t ^\\top \\bar h_s & dot \\\\\n",
      "h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n",
      "v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n",
      "\\end{cases}\n",
      "$$\n",
      "\n",
      "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class Attn(nn.Module):\n",
      "    def __init__(self, method, hidden_size, max_length=200):\n",
      "        super(Attn, self).__init__()\n",
      "        \n",
      "        self.method = method\n",
      "        self.hidden_size = hidden_size\n",
      "        \n",
      "        if self.method == 'general':\n",
      "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
      "\n",
      "        elif self.method == 'concat':\n",
      "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
      "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
      "\n",
      "    def forward(self, hidden, encoder_outputs):\n",
      "        seq_len = len(encoder_outputs)\n",
      "\n",
      "        # Create variable to store attention energies\n",
      "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
      "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
      "\n",
      "        # Calculate energies for each encoder output\n",
      "        for i in range(seq_len):\n",
      "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
      "\n",
      "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
      "        return F.softmax(attn_energies, dim=0).unsqueeze(0).unsqueeze(0)\n",
      "    \n",
      "    def score(self, hidden, encoder_output):\n",
      "        \n",
      "        if self.method == 'dot':\n",
      "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
      "            return energy\n",
      "        \n",
      "        elif self.method == 'general':\n",
      "            energy = self.attn(encoder_output)\n",
      "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
      "            return energy\n",
      "        \n",
      "        elif self.method == 'concat':\n",
      "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
      "            energy = torch.dot(self.other.view(-1), energy.view(-1))\n",
      "            return energy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weights, and apply those weights to the encoder outputs to get a context vector."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class AttnDecoderRNN(nn.Module):\n",
      "    def __init__(self, attn_model, hidden_size, vocab_size, n_layers=1, dropout_p=0.1):\n",
      "        super(AttnDecoderRNN, self).__init__()\n",
      "        \n",
      "        # Keep parameters for reference\n",
      "        self.attn_model = attn_model\n",
      "        self.hidden_size = hidden_size\n",
      "        self.vocab_size = vocab_size\n",
      "        self.n_layers = n_layers\n",
      "        self.dropout_p = dropout_p\n",
      "        \n",
      "        # Define layers\n",
      "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
      "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
      "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
      "        self.prob_gen = nn.Linear(hidden_size * 5, 1)\n",
      "        \n",
      "        # Choose attention model\n",
      "        if attn_model != 'none':\n",
      "            self.attn = Attn(attn_model, hidden_size)\n",
      "    \n",
      "    def forward(self, word_input, last_context, last_hidden, encoder_outputs, oov_indexes):\n",
      "        # Note: we run this one step at a time\n",
      "        \n",
      "        # Get the embedding of the current input word (last output word)\n",
      "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
      "        \n",
      "        # Combine embedded input word and last context, run through RNN\n",
      "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
      "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
      "\n",
      "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
      "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
      "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
      "        \n",
      "        # new\n",
      "        # Calculate probability of generating word from vocabulary conditioned on hidden, input, context\n",
      "        # for some reason, hidden is 2x1xn, so stretch into 1d\n",
      "        prob_gen_input_vec = torch.cat((rnn_input, context, hidden.view(1, 1, -1)), 2)\n",
      "        p_gen = F.sigmoid(self.prob_gen(prob_gen_input_vec))\n",
      "        #print(\"P_gen: \", p_gen)\n",
      "        \n",
      "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
      "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
      "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
      "        vocab_output = self.out(torch.cat((rnn_output, context), 1))\n",
      "        \n",
      "        # Pointer network probabilities\n",
      "        print(\"Vocab output: \", vocab_output.shape)\n",
      "        num_oov = max(oov_indexes, key=lambda x:x[1])[1] + 1 # number of distinct out of vocab tokens\n",
      "        pointer_output = Variable(torch.zeros(1, num_oov))\n",
      "        print(\"Pointer output: \", pointer_output.shape)\n",
      "        for pos, oov_index in oov_indexes:\n",
      "            #TODO: bugfix about in-place operations\n",
      "            pointer_output[0][oov_index] = pointer_output[0][oov_index] + attn_weights[0][0][pos]\n",
      "\n",
      "        output = F.log_softmax(torch.cat((p_gen * vocab_output, (1 - p_gen) * pointer_output), 1))\n",
      "        \n",
      "        # Return final output, hidden state, and attention weights (for visualization)\n",
      "        return output, context, hidden, attn_weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Training\n",
      "\n",
      "## Defining a training iteration\n",
      "\n",
      "To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
      "\n",
      "### Teacher Forcing and Scheduled Sampling\n",
      "\n",
      "\"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
      "\n",
      "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
      "\n",
      "The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "teacher_forcing_ratio = 0.5\n",
      "clip = 5.0\n",
      "\n",
      "def train(input_sentence, target_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
      "\n",
      "    # Convert sentences into variables\n",
      "    input_variable, input_OOV_list, input_OOV_indexes = variable_from_sentence(voc, input_sentence)\n",
      "    target_variable, _, _ = variable_from_sentence(voc, target_sentence)\n",
      "\n",
      "    # Zero gradients of both optimizers\n",
      "    encoder_optimizer.zero_grad()\n",
      "    decoder_optimizer.zero_grad()\n",
      "    loss = 0 # Added onto for each word\n",
      "\n",
      "    # Get size of input and target sentences\n",
      "    input_length = input_variable.size()[0]\n",
      "    target_length = target_variable.size()[0]\n",
      "\n",
      "    # Run words through encoder\n",
      "    encoder_hidden = encoder.init_hidden()\n",
      "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
      "    \n",
      "    # Prepare input and output variables\n",
      "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
      "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
      "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
      "    if USE_CUDA:\n",
      "        decoder_input = decoder_input.cuda()\n",
      "        decoder_context = decoder_context.cuda()\n",
      "\n",
      "    # Choose whether to use teacher forcing\n",
      "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
      "    if use_teacher_forcing:\n",
      "        \n",
      "        # Teacher forcing: Use the ground-truth target as the next input\n",
      "        for di in range(target_length):\n",
      "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, \n",
      "                                                                                         decoder_hidden, encoder_outputs,\n",
      "                                                                                         input_OOV_indexes)\n",
      "            if target_variable[di] in voc.word2index:\n",
      "                loss += criterion(decoder_output, target_variable[di])\n",
      "            else:\n",
      "                loss += criterion(decoder_output, voc.n_words + input_OOV_indexes[di])\n",
      "            decoder_input = target_variable[di] # Next target is next input\n",
      "\n",
      "    else:\n",
      "        # Without teacher forcing: use network's own prediction as the next input\n",
      "        for di in range(target_length):\n",
      "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context,\n",
      "                                                                                         decoder_hidden, encoder_outputs,\n",
      "                                                                                         input_OOV_indexes)\n",
      "            if target_variable[di] in voc.word2index:\n",
      "                loss += criterion(decoder_output, target_variable[di])\n",
      "            else:\n",
      "                loss += criterion(decoder_output, voc.n_words + input_OOV_indexes[di])\n",
      "            \n",
      "            # Get most likely word index (highest value) from output\n",
      "            topv, topi = decoder_output.data.topk(1)\n",
      "            ni = topi[0][0]\n",
      "            \n",
      "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
      "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
      "\n",
      "            # Stop at end of sentence (not necessary when using known targets)\n",
      "            if ni == EOS_token: break\n",
      "\n",
      "    # Backpropagation\n",
      "    loss.backward()\n",
      "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
      "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
      "    encoder_optimizer.step()\n",
      "    decoder_optimizer.step()\n",
      "    \n",
      "    return loss.data[0] / target_length"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally helper functions to print time elapsed and estimated time remaining, given the current time and progress."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def as_minutes(s):\n",
      "    m = math.floor(s / 60)\n",
      "    s -= m * 60\n",
      "    return '%dm %ds' % (m, s)\n",
      "\n",
      "def time_since(since, percent):\n",
      "    now = time.time()\n",
      "    s = now - since\n",
      "    es = s / (percent)\n",
      "    rs = es - s\n",
      "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "attn_model = 'concat'\n",
      "hidden_size = 500\n",
      "n_layers = 2\n",
      "dropout_p = 0.05\n",
      "\n",
      "# Initialize models\n",
      "encoder = EncoderRNN(voc.n_words, hidden_size, n_layers)\n",
      "decoder = AttnDecoderRNN(attn_model, hidden_size, voc.n_words, n_layers, dropout_p=dropout_p)\n",
      "\n",
      "# Move models to GPU\n",
      "if USE_CUDA:\n",
      "    encoder.cuda()\n",
      "    decoder.cuda()\n",
      "\n",
      "# Initialize optimizers and criterion\n",
      "learning_rate = 0.0001\n",
      "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
      "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
      "criterion = nn.NLLLoss()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Configuring training\n",
      "n_epochs = 50\n",
      "plot_every = 20\n",
      "print_every = 1\n",
      "\n",
      "# Keep track of time elapsed and running averages\n",
      "start = time.time()\n",
      "plot_losses = []\n",
      "print_loss_total = 0 # Reset every print_every\n",
      "plot_loss_total = 0 # Reset every plot_every\n",
      "\n",
      "# Begin!\n",
      "for epoch in range(1, n_epochs + 1):\n",
      "    \n",
      "    # Get training data for this cycle\n",
      "    pair = random.choice(pairs)\n",
      "\n",
      "    # Run the train function\n",
      "    loss = train(pair[0], pair[1], encoder, \n",
      "                 decoder, encoder_optimizer, \n",
      "                 decoder_optimizer, \n",
      "                 criterion)\n",
      "\n",
      "    # Keep track of loss\n",
      "    print_loss_total += loss\n",
      "    plot_loss_total += loss\n",
      "\n",
      "    if epoch == 0: continue\n",
      "\n",
      "    if epoch % print_every == 0:\n",
      "        print_loss_avg = print_loss_total / print_every\n",
      "        print_loss_total = 0\n",
      "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
      "        print(print_summary)\n",
      "\n",
      "    if epoch % plot_every == 0:\n",
      "        plot_loss_avg = plot_loss_total / plot_every\n",
      "        plot_losses.append(plot_loss_avg)\n",
      "        plot_loss_total = 0"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sentence shape:  torch.Size([952, 1])\n",
        "Sentence shape:  torch.Size([49, 1])\n",
        "Vocab output: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " torch.Size([1, 103])\n",
        "Pointer output:  torch.Size([1, 319])\n"
       ]
      },
      {
       "ename": "RuntimeError",
       "evalue": "in-place operations can be only used on variables that don't share storage with any other variables, but detected that there are 2 objects sharing it",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-68-b791e75b0d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                  \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                  \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                  criterion)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-65-6a282b3881d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_sentence, target_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     37\u001b[0m             decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, \n\u001b[1;32m     38\u001b[0m                                                                                          \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                                                                          input_OOV_indexes)\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-64-52026e43339d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_input, last_context, last_hidden, encoder_outputs, oov_indexes)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moov_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#print(pointer_output.shape, oov_index, attn_weights.shape, pos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mpointer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moov_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpointer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moov_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMaskedFill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSetItem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: in-place operations can be only used on variables that don't share storage with any other variables, but detected that there are 2 objects sharing it"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting training loss\n",
      "\n",
      "Plotting is done with matplotlib, using the array `plot_losses` that was created while training."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "\n",
      "def show_plot(points):\n",
      "    plt.figure()\n",
      "    fig, ax = plt.subplots()\n",
      "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
      "    ax.yaxis.set_major_locator(loc)\n",
      "    plt.plot(points)\n",
      "\n",
      "show_plot(plot_losses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Evaluating the network\n",
      "\n",
      "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def evaluate(sentence, max_length=200):\n",
      "    input_variable, input_OOV_list, input_OOV_indexes = variable_from_sentence(voc, sentence)\n",
      "    input_length = input_variable.size()[0]\n",
      "    \n",
      "    # Run through encoder\n",
      "    encoder_hidden = encoder.init_hidden()\n",
      "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
      "\n",
      "    # Create starting vectors for decoder\n",
      "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
      "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
      "    if USE_CUDA:\n",
      "        decoder_input = decoder_input.cuda()\n",
      "        decoder_context = decoder_context.cuda()\n",
      "\n",
      "    decoder_hidden = encoder_hidden\n",
      "    \n",
      "    decoded_words = []\n",
      "    decoder_attentions = torch.zeros(max_length, max_length)\n",
      "    \n",
      "    # Run through decoder\n",
      "    for di in range(max_length):\n",
      "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context,\n",
      "                                                                                     decoder_hidden, encoder_outputs,\n",
      "                                                                                     input_OOV_indexes)\n",
      "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
      "\n",
      "        # Choose top word from output\n",
      "        topv, topi = decoder_output.data.topk(1)\n",
      "        ni = topi[0][0]\n",
      "        if ni == EOS_token:\n",
      "            decoded_words.append('<EOS>')\n",
      "            break\n",
      "        else:\n",
      "            decoded_words.append(voc.index2word[ni])\n",
      "            \n",
      "        # Next input is chosen word\n",
      "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
      "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
      "    \n",
      "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def evaluate_randomly():\n",
      "    pair = random.choice(pairs)\n",
      "    \n",
      "    output_words, decoder_attn = evaluate(pair[0])\n",
      "    output_sentence = ' '.join(output_words)\n",
      "    \n",
      "    print('>', pair[0])\n",
      "    print('=', pair[1])\n",
      "    print('<', output_sentence)\n",
      "    print('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_randomly()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Visualizing attention\n",
      "\n",
      "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
      "\n",
      "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_words, attentions = evaluate(\"house speaker newt gingrich who orchestrated the republican revolution of recent years and is overseeing the impeachment inquiry into president clinton was driven from office friday by a party that swiftly turned on him after its unexpected losses in tuesday s midterm elections .\")\n",
      "plt.matshow(attentions.numpy())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a better viewing experience we will do the extra work of adding axes and labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def show_attention(input_sentence, output_words, attentions):\n",
      "    # Set up figure with colorbar\n",
      "    fig = plt.figure()\n",
      "    ax = fig.add_subplot(111)\n",
      "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
      "    fig.colorbar(cax)\n",
      "\n",
      "    # Set up axes\n",
      "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
      "    ax.set_yticklabels([''] + output_words)\n",
      "\n",
      "    # Show label at every tick\n",
      "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
      "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
      "\n",
      "    plt.show()\n",
      "    plt.close()\n",
      "\n",
      "def evaluate_and_show_attention(input_sentence):\n",
      "    output_words, attentions = evaluate(input_sentence)\n",
      "    print('input =', input_sentence)\n",
      "    print('output =', ' '.join(output_words))\n",
      "    show_attention(input_sentence, output_words, attentions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_and_show_attention(\"a south korean lawmaker said friday communist north korea could be producing plutonium and could have more secret underground nuclear facilities than already feared .\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_and_show_attention(\"egyptian president hosni mubarak met here sunday with syrian president hafez assad to try to defuse growing tension between syria and turkey .\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_and_show_attention(\"police and soldiers on friday blocked off the street in front of a house where members of a terrorist gang are believed to have assembled the bomb that blew up the u .s . embassy killing people .\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_and_show_attention(\"premier battled tuesday for any votes freed up from a split in a far left party but said he will resign if he loses a confidence vote expected later this week .\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "# To do\n",
      "\n",
      "* Try with a different dataset\n",
      "    * cnn/dailymail\n",
      "    * gigawords\n",
      "    * standford\n",
      "    * Human &rarr; Machine (e.g. IOT commands)\n",
      "    * Chat &rarr; Response\n",
      "    * Question &rarr; Answer\n",
      "* Replace the embedding pre-trained word embeddings such as word2vec or GloVe\n",
      "* Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
      "* Try different RNN layers like lstm.\n",
      "* Add batch operation for GPU training\n",
      "* Add beam search on decoder side when dealing with long documents.\n",
      "* Control the Different output size\n",
      "* Dig out other tricks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}