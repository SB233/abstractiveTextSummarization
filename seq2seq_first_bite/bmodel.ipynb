{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/eBRPvWB.png)\n",
    "\n",
    "# Bahdanau Model\n",
    "\n",
    "Implementation of RNN sequence-to-sequence model from Bahdanau et al. as a basis for more sophisticated models such as reinforced, hierarchical-attention, or topic-focused summarization.\n",
    "\n",
    "**Note**: We use the CNN/Dailymail dataset from [@JafferWilson](https://github.com/JafferWilson/Process-Data-of-CNN-DailyMail)'s Github account. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sequence to Sequence model\n",
    "\n",
    "A [Sequence to Sequence network](http://arxiv.org/abs/1409.3215), or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two separate RNNs called the **encoder** and **decoder**. The encoder reads an input sequence one item at a time, and outputs a vector at each step. The final output of the encoder is kept as the **context** vector. The decoder uses this context vector to produce a sequence of outputs one step at a time.\n",
    "\n",
    "![](https://i.imgur.com/tVtHhNp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Attention Mechanism\n",
    "\n",
    "The fixed-length vector carries the burden of encoding the the entire \"meaning\" of the input sequence, no matter how long that may be. With all the variance in language, this is a very hard problem. Imagine two nearly identical sentences, twenty words long, with only one word different. Both the encoders and decoders must be nuanced enough to represent that change as a very slightly different point in space.\n",
    "\n",
    "The **attention mechanism** [introduced by Bahdanau et al.](https://arxiv.org/abs/1409.0473) addresses this by giving the decoder a way to \"pay attention\" to parts of the input, rather than relying on a single vector. For every step the decoder can select a different part of the input sentence to consider.\n",
    "\n",
    "![](https://i.imgur.com/5y6SCvU.png)\n",
    "\n",
    "Attention is calculated with another feedforward layer in the decoder. This layer will use the current input and hidden state to create a new vector, which is the same size as the input sequence (in practice, a fixed maximum length). This vector is processed through softmax to create *attention weights*, which are multiplied by the encoders' outputs to create a new context vector, which is then used to predict the next output.\n",
    "\n",
    "![](https://i.imgur.com/K1qMPxs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "You will need [PyTorch](http://pytorch.org/) to build and train the models, and [matplotlib](https://matplotlib.org/) for plotting training and visualizing attention outputs later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6,7\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will also define a constant to decide whether to use the GPU (with CUDA specifically) or the CPU. **If you don't have a GPU, set this to `False`**. Later when we create tensors, this variable will be used to decide whether we keep them on CPU or move them to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data Files\n",
    "\n",
    "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language. On other tutorials,  they adopt an initial embedding matrix built from [GloVe](http://nlp.stanford.edu/projects/glove/), which can be tested afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Voc` which has word &rarr; index (`word2index`) and index &rarr; word (`index2word`) dictionaries, as well as a count of each word `word2count` to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and decoding files\n",
    "\n",
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all description &rarr; headline, so if we want to generate text from headline &rarr; description I added the `reverse` flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(csvname, reverse=False):\n",
    "    print(\"Reading csv...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    with open('../data/%s.csv' % csvname, 'r') as csvfile:\n",
    "        pairs = []\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        for line in csvreader:\n",
    "            try:\n",
    "                pairs.append([normalize_string(line[1]), normalize_string(line[2])])\n",
    "            except IndexError:\n",
    "                pass\n",
    "    \n",
    "    # Reverse pairs, make Lang instances (not supported)\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        voc = Voc(csvname)\n",
    "    else:\n",
    "        voc = Voc(csvname)\n",
    "\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_stories(pathname, reverse=False, num_files=100):\n",
    "    print(\"Reading csv...\")\n",
    "    \n",
    "    # Get the first num_files file names\n",
    "    files = os.listdir('../data/%s' % pathname)[:num_files]\n",
    "    \n",
    "    # Boolean flag for summary sentences\n",
    "    summary_next = False\n",
    "    \n",
    "    # Read each file and extract vocab\n",
    "    pairs = []\n",
    "    for filename in files:\n",
    "        with open('../data/%s/%s' % (pathname, filename), 'r') as story_file:\n",
    "            story = ''\n",
    "            summary = ''\n",
    "            for line in story_file:\n",
    "                if line == '\\n': continue # ignore blank lines\n",
    "                if line == '@highlight\\n': summary_next = True\n",
    "                else:\n",
    "                    if summary_next: summary += line\n",
    "                    else: story += line\n",
    "                    summary_next = False\n",
    "            pairs.append([normalize_string(story), normalize_string(summary)])\n",
    "            \n",
    "    # Reverse pairs, make Lang instances (not supported)\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "    voc = Voc(pathname)\n",
    "\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "Following is the main pre-processing function. Reads some articles and generates article-summary pairs and a comprehensive vocabulary from the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv...\n",
      "Read 100 article-summary pairs\n",
      "Indexing words...\n",
      "    found 9110 words\n",
      "as a young girl chelsea clinton learned to keep secrets . but she also learned to call the secret service pigs . that s a claim from former white house florist ronn payne retold in a new book based on interviews with more than members of the presidential mansion s domestic staff . as he walked into the second floor kitchen one day he saw chelsea talking on the phone . a member of her secret service protective detail came in behind him to take the clintons only child to school . oh i ve got to go . the pigs are here she told her phone pal according to payne using a s era epithet for law enforcement . faced with an angry agent who reminded her in no uncertain terms that it was his job to protect her chelsea replied well that s what my mother and father call you . scroll down for video pigs chelsea clinton lrb right in rrb allegedly referred to the secret service with an offensive counter culture epithet and said she learned it from her parents shame chelsea lrb center rrb accompanied her parents and their dog to the marine one chopper in just a day after the president admitted to marital infidelities chelsea now shares leadership of the bill hillary and chelsea clinton foundation which would n t respond to questions about the pigs episode while the political world was focused tuesday on republican rand paul s presidential coming out party politico published an excerpt of the residence inside the private world of the white house . the book that could prove problematic for democratic front runner hillary clinton the former first lady senator and secretary of state . the bill hillary and chelsea clinton foundation did not respond to a request for comment about whether payne s recollection is accurate . chelsea now runs the family philanthropy along with her parents . but that snippet from america s hidden history is just the tip of the iceberg . skip allen a clinton era white house usher a high ranking butler said in the book that bill and hillary were about the most paranoid people i d ever seen in my life . pitched battles hillary lrb left with the former president in august rrb once threw a heavy object believed by staff to have been a table lamp across the room kate andersen brower writes in her new book lrb right rrb allen who served under multiple presidents told author kate anderson brower that he preferred to work for first families he genuinely liked rather than pretending he had warm feeligns for his employers . but we pretend very well he added . another usher chris emery found himself uncerimoniously fired for helping former first lady barbara bush with technical computer questions . he had taught her how to use a pc during president george h . w . bush s one term in office . when the clintons saw a log of his calls they feared he was leaking their secrets to the bush clan something he insists he never did . i was out of work for a year emery says in the book . they ripped the rug right out from under me . you wonder what they d do to someone who s really powerful . at the height of the sex scandal that saw bill clinton admitting he frolicked with intern monica lewinsky in the oval office one white house maid was astonished to find the first couple s marital bed drenched in blood according to brower . explaining an injury the president claimed publicly that he had hurt himself running into the bathroom door in the middle of the night . but one white house domestic told brower that we re pretty sure hillary clocked him with a book . disputes white house domestic employees said they heard hillary clock him with a book during the monica lewinsky scandal there were at least books on the bedside table for his betrayed wife to choose from she writes including the bible . for at least three months in according to the residence the leader of the free world slept on a sofa in a private study attached to their bedroom . most of the women on the residence staff thought he got what he deserved . and brower s research surfaced white house residence staffers who described how the first couple sometimes got into pitched battles during their eight years in washington shocking staff with their vicious cursing . payne once came upon two butlers listening to a particularly aggressive dispute through a doorway . he heard mrs clinton yell g ddamn b stard he told brower . hillary subsequently threw a heavy object at him in brower s telling . the first lady s temper was notoriously short during the early months of the scandal according to the book . when butler james hall was serving tea and coffee during a reception for a foreign leader and another employee forgot to clear the china she snapped you must have been staring into space ! he recalled mrs . clinton saying . i had to take the prime minister s wife s cup . . . . she was finished and looking for some place to put it . affair former white house staff revealed their secrets about daily life inside the presidential mansion including how they knew bill clinton and intern monica lewinsky lrb seen together rrb were sexually involved happy birthday mr . president when jackie kennedy was away a white house worker stumbled across her husband john f . kennedy lrb pictured right speaking to marilyn monroe in rrb swimming naked in the pool with other women hall sais he was n t asked back to perform his duties for a month . other presidents figure in brower s book including john f . kennedy . when then first lady jackie kennedy was away at the couple s farm in virginia a white house worker apparently stumbled across her husband swimming naked in the mansion s pool . and jfk was not alone he was apparently joined by several female white house secretaries . naked women were also sighted on the second floor of the building when mrs . kennedy was away . other revelations in the book include jimmy carter s sons passion for bongs their rooms were constantly filled with smoke and their father s uncontrollable sobbing after losing the election . and white house domestic employees told brower how lyndon johnson adored washing in a specially built powerful shower while nancy reagan rejected white house chefs meals and gave them seemingly impossible deadlines .\n",
      "\n",
      "stunning tale came from white house domestic help who tended to the clintons every need during the s book published today is based on more than interviews with ordinary non political staff who ran america s presidential mansion one former head of the household staff said they were about the most paranoid people i d ever seen in my life another staff member said he was fired after he helped former first lady barbara bush with her computer because clintons feared he was gossiping a third recalled listening as bill and hillary fought during the monica lewinsky saga with hillary once calling him a g ddamn b stard \n"
     ]
    }
   ],
   "source": [
    "def prepare_data(pathname, reverse=False):\n",
    "    voc, pairs = read_stories(pathname, reverse)\n",
    "    print(\"Read %s article-summary pairs\" % len(pairs))\n",
    "\n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        voc.index_words(pair[0])\n",
    "        voc.index_words(pair[1])\n",
    "    print(\"    found %d words\" % voc.n_words)\n",
    "\n",
    "    return voc, pairs\n",
    "\n",
    "voc, pairs = prepare_data('dm_stories_tokenized', False)\n",
    "\n",
    "pair = random.choice(pairs)\n",
    "print(pair[0]+'\\n')\n",
    "print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning training data into Tensors/Variables\n",
    "\n",
    "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a Tensor, where each word is replaced with the index (from the Lang indexes made earlier). While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)\n",
    "\n",
    "A Tensor is a multi-dimensional array of numbers, defined with some type e.g. FloatTensor or LongTensor. In this case we'll be using LongTensor to represent an array of integer indexes.\n",
    "\n",
    "Trainable PyTorch modules take Variables as input, rather than plain Tensors. A Variable is basically a Tensor that is able to keep track of the graph state, which is what makes autograd (automatic calculation of backwards gradients) possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(voc, sentence):\n",
    "    indexes = indexes_from_sentence(voc, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(voc, pair[0])\n",
    "    target_variable = variable_from_sentence(voc, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4326\n",
      "  493\n",
      " 1952\n",
      "  634\n",
      "   57\n",
      "[torch.LongTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_pair = variables_from_pair(random.choice(pairs))\n",
    "input_variable = training_pair[0]\n",
    "target_variable = training_pair[1]\n",
    "print(input_variable[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder\n",
    "\n",
    "<img src=\"images/encoder-network.png\" style=\"float: right\" />\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Bahdanau et al. model\n",
    "\n",
    "The attention model in [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) is described as the following series of equations.\n",
    "\n",
    "Each decoder output is conditioned on the previous outputs and some $\\mathbf x$, where $\\mathbf x$ consists of the current hidden state (which takes into account previous outputs) and the attention \"context\", which is calculated below. The function $g$ is a fully-connected layer with a nonlinear activation, which takes as input the values $y_{i-1}$, $s_i$, and $c_i$ concatenated.\n",
    "\n",
    "$$\n",
    "p(y_i \\mid \\{y_1,...,y_{i-1}\\},\\mathbf{x}) = g(y_{i-1}, s_i, c_i)\n",
    "$$\n",
    "\n",
    "The current hidden state $s_i$ is calculated by an RNN $f$ with the last hidden state $s_{i-1}$, last decoder output value $y_{i-1}$, and context vector $c_i$.\n",
    "\n",
    "In the code, the RNN will be a `nn.GRU` layer, the hidden state $s_i$ will be called `hidden`, the output $y_i$ called `output`, and context $c_i$ called `context`.\n",
    "\n",
    "$$\n",
    "s_i = f(s_{i-1}, y_{i-1}, c_i)\n",
    "$$\n",
    "\n",
    "The context vector $c_i$ is a weighted sum of all encoder outputs, where each weight $a_{ij}$ is the amount of \"attention\" paid to the corresponding encoder output $h_j$.\n",
    "\n",
    "$$\n",
    "c_i = \\sum_{j=1}^{T_x} a_{ij} h_j\n",
    "$$\n",
    "\n",
    "... where each weight $a_{ij}$ is a normalized (over all steps) attention \"energy\" $e_{ij}$ ...\n",
    "\n",
    "$$\n",
    "a_{ij} = \\dfrac{exp(e_{ij})}{\\sum_{k=1}^{T} exp(e_{ik})}\n",
    "$$\n",
    "\n",
    "... where each attention energy is calculated with some function $a$ (such as another linear layer) using the last hidden state $s_{i-1}$ and that particular encoder output $h_j$:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(s_{i-1}, h_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Bahdanau et al. model\n",
    "\n",
    "In summary our decoder should consist of four main parts - an embedding layer turning an input word into a vector; a layer to calculate the attention energy per encoder output; a RNN layer; and an output layer.\n",
    "\n",
    "The decoder's inputs are the last RNN hidden state $s_{i-1}$, last output $y_{i-1}$, and all encoder outputs $h_*$.\n",
    "\n",
    "* embedding layer with inputs $y_{i-1}$\n",
    "    * `embedded = embedding(last_rnn_output)`\n",
    "* attention layer $a$ with inputs $(s_{i-1}, h_j)$ and outputs $e_{ij}$, normalized to create $a_{ij}$\n",
    "    * `attn_energies[j] = attn_layer(last_hidden, encoder_outputs[j])`\n",
    "    * `attn_weights = normalize(attn_energies)`\n",
    "* context vector $c_i$ as an attention-weighted average of encoder outputs\n",
    "    * `context = sum(attn_weights * encoder_outputs)`\n",
    "* RNN layer(s) $f$ with inputs $(s_{i-1}, y_{i-1}, c_i)$ and internal hidden state, outputting $s_i$\n",
    "    * `rnn_input = concat(embedded, context)`\n",
    "    * `rnn_output, rnn_hidden = rnn(rnn_input, last_hidden)`\n",
    "* an output layer $g$ with inputs $(y_{i-1}, s_i, c_i)$, outputting $y_i$\n",
    "    * `output = out(embedded, rnn_output, context)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        print(encoder_outputs.size())\n",
    "\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        context = context.squeeze(0) # B x N\n",
    "        \n",
    "        print(\"Context size: \", context.size())\n",
    "        print(\"RNN out size: \", output.size())\n",
    "        print(\"Output cat Context size: \", torch.cat((output, context), 1).shape)\n",
    "        print(\"Output size: \", self.out(torch.cat((output, context), 1)).shape)\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Luong et al. model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) by Luong et al. describe a few more attention models that offer improvements and simplifications. They describe a few \"global attention\" models, the distinction between them being the way the attention scores are calculated.\n",
    "\n",
    "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1:\n",
    "\n",
    "$$\n",
    "a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n",
    "$$\n",
    "\n",
    "The specific \"score\" function that compares two states is either *dot*, a simple dot product between the states; *general*, a a dot product between the decoder hidden state and a linear transform of the encoder state; or *concat*, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
    "\n",
    "$$\n",
    "score(h_t, \\bar h_s) =\n",
    "\\begin{cases}\n",
    "h_t ^\\top \\bar h_s & dot \\\\\n",
    "h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n",
    "v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = torch.dot(self.other.view(-1), energy.view(-1))\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weights, and apply those weights to the encoder outputs to get a context vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the models\n",
    "\n",
    "To make sure the Encoder and Decoder model are working (and working together) we'll do a quick test with fake word inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2)\n",
      ")\n",
      "BahdanauAttnDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=20, out_features=10)\n",
      "  )\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear(in_features=20, out_features=10)\n",
      ")\n",
      "torch.Size([3, 1, 10])\n",
      "Context size:  torch.Size([1, 10])\n",
      "RNN out size:  torch.Size([1, 10])\n",
      "Output cat Context size:  torch.Size([1, 20])\n",
      "Output size:  torch.Size([1, 10])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([3, 1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirm2/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/kabirm2/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 10])\n",
      "RNN out size:  torch.Size([1, 10])\n",
      "Output cat Context size:  torch.Size([1, 20])\n",
      "Output size:  torch.Size([1, 10])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([3, 1, 10])\n",
      "Context size:  torch.Size([1, 10])\n",
      "RNN out size:  torch.Size([1, 10])\n",
      "Output cat Context size:  torch.Size([1, 20])\n",
      "Output size:  torch.Size([1, 10])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = BahdanauAttnDecoderRNN(10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     encoder_test = nn.DataParallel(encoder_test)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     decoder_test = nn.DataParallel(decoder_test)\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "    \n",
    "\n",
    "for i in range(3):\n",
    "    #def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "    decoder_output, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], \n",
    "                                                                                 decoder_hidden, \n",
    "                                                                                 encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 19 \n",
       "    0     0     0     0     0     0     0\n",
       "[torch.FloatTensor of size 1x20]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(1,10)\n",
    "b = torch.zeros(1,10)\n",
    "torch.cat((a,b), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Defining a training iteration\n",
    "\n",
    "To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
    "\n",
    "### Teacher Forcing and Scheduled Sampling\n",
    "\n",
    "\"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
    "\n",
    "The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9110\n"
     ]
    }
   ],
   "source": [
    "print(voc.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                            decoder_hidden, encoder_outputs)\n",
    "            print(\"Decoder output[0]: \", decoder_output[0])\n",
    "            print(\"Target variable[0]: \", target_variable[0])\n",
    "            ###########################################\n",
    "            # print(decoder_output.size(), target_variable[di].size())\n",
    "            \n",
    "            print(decoder_output.shape, target_variable[di].shape)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #print(criterion(decoder_output[0], \n",
    "            #                target_variable[di]).size())\n",
    "            \n",
    "            ###########################################\n",
    "            # print(decoder_output.size(), target_variable[di].size())\n",
    "            print(\"Decoder output[0]: \", decoder_output[0])\n",
    "            print(\"Target variable[0]: \", target_variable[0])\n",
    "            print(decoder_output.shape, target_variable[di].shape)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally helper functions to print time elapsed and estimated time remaining, given the current time and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running training\n",
    "\n",
    "With everything in place we can actually initialize a network and start training.\n",
    "\n",
    "To start, we initialize models, optimizers, and a loss function (criterion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(voc.n_words, hidden_size, n_layers)\n",
    "decoder = BahdanauAttnDecoderRNN(hidden_size, voc.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up variables for plotting and tracking progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 500\n",
    "plot_every = 10\n",
    "print_every = 20\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually train, we call the train function many times, printing a summary as we go.\n",
    "\n",
    "*Note:* If you run this notebook you can train, interrupt the kernel, evaluate, and continue training later. You can comment out the lines above where the encoder and decoder are initialized (so they aren't reset) or simply run the notebook starting from the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirm2/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/kabirm2/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([614, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([902, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 57\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n",
      "torch.Size([1217, 1, 500])\n",
      "Context size:  torch.Size([1, 500])\n",
      "RNN out size:  torch.Size([1, 500])\n",
      "Output cat Context size:  torch.Size([1, 1000])\n",
      "Output size:  torch.Size([1, 9110])\n",
      "Decoder output[0]:  Variable containing:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      " ⋮ \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 9110]\n",
      "\n",
      "Target variable[0]:  Variable containing:\n",
      " 5213\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([1, 9110]) torch.Size([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b419b78689f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                  \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                  \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                  criterion)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-8264976d1cde>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, \n",
    "                 decoder, encoder_optimizer, \n",
    "                 decoder_optimizer, \n",
    "                 criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss\n",
    "\n",
    "Plotting is done with matplotlib, using the array `plot_losses` that was created while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the network\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=200):\n",
    "    input_variable = variable_from_sentence(voc, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(voc.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing attention\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
    "\n",
    "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\"house speaker who orchestrated the republican revolution of recent years and is overseeing the impeachment inquiry into president clinton was driven from office friday by a party that swiftly turned on him after its unexpected losses in tuesday s mid term elections .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(20)\n",
    "    \n",
    "    # fig.set_figheight(50)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone', aspect = 1)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"a south korean lawmaker said friday communist north korea could be producing bombs and could have more secret underground nuclear facilities than already feared .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "evaluate_and_show_attention(' '.join(pairs[0]))\n",
    "#evaluate_and_show_attention(\"egyptian president hosni mubarak met here sunday with syrian president hafez assad to try to defuse growing tension between syria and turkey .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"police and soldiers on friday blocked off the street in front of a house where members of a terrorist gang are believed to have assembled the bomb that blew up the u .s . embassy killing people .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"premier battled tuesday for any votes freed up from a split in a far left party but said he will resign if he loses a confidence vote expected later this week .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# To do\n",
    "\n",
    "* Try with a different dataset\n",
    "    * cnn/dailymail\n",
    "    * gigawords\n",
    "    * standford\n",
    "    * Human &rarr; Machine (e.g. IOT commands)\n",
    "    * Chat &rarr; Response\n",
    "    * Question &rarr; Answer\n",
    "* Replace the embedding pre-trained word embeddings such as word2vec or GloVe\n",
    "* Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
    "* Try different RNN layers like lstm.\n",
    "* Add batch operation for GPU training\n",
    "* Add beam search on decoder side when dealing with long documents.\n",
    "* Control the Different output size\n",
    "* Dig out other tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
